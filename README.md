# mg-lora-rag

Notebook-first experiments for LoRA fine-tuning and comparison of two models (Gemma 3 4B and Llama 3.2 3B Instruct).
Vamos a hacer un fine-tuning de ambos modelos usando LoRA y comparar sus resultados en una tarea de QA basada en el dataset "yunfan-y/trump-qa" de huggingface.
El objetivo es evaluar cuál de los dos modelos se adapta mejor a la tarea tras el fine-tuning con LoRA, considerando métricas de rendimiento y calidad de las respuestas generadas.
